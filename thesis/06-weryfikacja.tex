\documentclass[00-praca-magisterska.tex]{subfiles}
\begin{document}

\chapter{Weryfikacja}

W tym rozdziale wracamy do wymagań stawianych przed narzędziem na początku
pracy. James Bach w \cite{snake-oil} pisze, że próby stworzenia systemów
automatyzacji często kończą się porażką ponieważ tworzy się je mniej starannie
niż właściwie produkty. W naszym wypadku to system automatyzacji był tym
właściwym produktem, mimo to należy spojrzeć krytycznym okiem na końcowy wynik.

\section{Wymagania}

Jednym z podstawowym wymaganiem była możliwosć definiowania testu.
Zastosowaliśmy rozwiązanie oparte o język Python i stworzone przez nas API, co
szeroko opisaliśmy w rozdziale \ref{arete-master-config}.

Łączenie ze zdalnymi urządzeniami możliwe jest przy użyciu wtyczek typu
\code{ConnectionPlugin}. Dostępna jest wtyczka oparta o protokół TCP/IP oraz
jej wersja korzystająca z tunelu SSH.

Konfiguracja zdalnych urządzeń jest przeprowadzana w drugiej fazie testu, tj.
fazie konfiguracji urządzeń oraz fazie czwartej czyli przywracaniu
konfiguracji (patrz sekcja \ref{arete-arch}). Interfejs programy opisujemy w
sekcji \ref{arete-master-drivers}.

Przesyłanie zasobów wymaganych w testach dokumentujemy w sekcji
\ref{arete-master-resources}. Ze względu na różne możliwości komunikacyjne
sprzętu sieciowego, stworzyliśmy uniwersalny interfejs programy, który można
dowolnie rozbudować na własne potrzeby.

Funkcjonalność zwiazana z uruchamieniem poleceń na zdalnych urządzeniach
zrealizowane jest w dwóch częściach. Moduł Master analizuje pliki z definicją
testu i tworzy listy komend do wykonania na konkretnych urządzeniach. Za samo
wykonanie komend odpowiedzialny jest moduł Slave.

Pobieranie wyników ze zdalnych urządzeń odbywa się korzystając z prostego
protokołu między modułami Master oraz Slave. Katalogowanie wyników z wielu
testów zrealizowaliśmy przechowując wyniki w bazie danych SQLite, której
strukturę przedstawiamy w sekcji \ref{arete-master-db}.

Aby synchronizować w czasie start testu, moduł Master przesyła do urządzeń
informację o godzinie, w której tes ma się rozpocząć. Udostępniliśmy prosty
mechanizm synchronizacji między urządzeniami. Możliwe jest też poleganie
wyłącznie na zegarach systemowych urządzeń, co jest przydatne, jeśli w sieci
funkcjonuje inny mechanizm synchronizacji czasu.

Dla testów, których przebieg uniemożliwia utrzymywanie ciągłego połączenia
między modułami Master i Slave, istnieje możliwość rozłączenia na czas trwania
testu. W tym celu każde wykonanie przypadku testowego otrzymuje nowy
identyfikator aby po ponownym nawiązaniu połączenia moduł Master mógł określić,
jakie wyniki chce otrzymać. W przypadku testów, których zakończenie wymaga
kooperacji pomiędzy modułami Slave, rozłączenie na czas jego wykonania nie jest
możliwe, komunikują one bowiem za pośrednictwem modułu Master. Mechanizm ten
opisany jest w sekcji \ref{arete-master-others}.

Wspomniany mechanizm powiadomień został pierwotnie zaimplementowany aby
umożliwić zakończenie testu w momencie, gdy wykonanie zakończą wszystkie
uczestniczące urządzenia. Inny przypadek, w którym test kończy się gdy wybrane
urządzenie zakończy test, również realizowany jest przy użyciu powiadomień.
Zakończenie testu w wybranym momencie czasowym to odzielny mechanizm, opisany w
sekcji \ref{arete-master-config-plan}.

Realizację wszystkich wymagań testowaliśmy w czasie implementacji za pomocą
tworzonych testów jednostkowych\footnote{\ang{unit test}} oraz wykonując
przedstawione w rozdziale \ref{demonstracja-arete} przypadki testowe.
Funkcjonalność Arete spełnia nasze oczekiwania.

\section{Pokrewne rozwiązania}
\label{dostepne-rozwiazania}

Istnieje wiele programów rozwiązujących problem automatyzacji testowania, które
w różnym stopniu i na różnych poziomach pozwalają na ułatwienie i przyspieszenie
przeprowadzania testów aplikacji i protokołów sieciowych. Jednak spośród znanych
nam rozwiązań, żadne nie pozwalało przeprowadzić takiego rodzaju testów, jakie
próbowaliśmy wykonać. W tym rozdziaje prezentujemy narzędzia i technologie,
które stanowiły dla nas punkt odniesienia w czasie pracy nad Arete.

\subsection{ASN.1 i ECN}
\label{asn}
ASN.1 (Abstract Syntax Notation One) jest to standard ITU-T/ISO służący do opisu
struktur reprezentujących dane w sposób umożliwiający ich kodowanie, transmisję
i dekodowanie. Dostarcza on formalnej notacji do opisu struktur w sposób
niezwiązany z reprezentacją sprzętową.

ASN.1 definiuje sposób opisu danych. Jest on niezależny od metod ich kodowania,
przedstawionych w oddzielnych dokumentach. Przykładowe metody to:
\begin{itemize}
\item BER (Basic Encoding Rules),
\item PER (Packed Encoding Rules),
\item XER (XML Encoding Rules).
\end{itemize}

Wykorzystanie formalnych metod opisu pozwala na automatyczne tworzenie koderów i
dekoderów. W przypadku pracy z istniejącymi protokołami, PDU zwykle na stałe
wiąże przenoszone dane z ich kodowaniem. Przykładem może być opis pakietów TCP w
RFC 793, gdzie dane (np. numer sekwencyjny) i ich kodowanie (rozmiar i
położenie bitów w pakiecie) określone są w tym samym miejscu. Nie ma więc
podziału między semantyką informacji i jej bitową reprezentacją. Korzystanie z
ASN.1 w takich wypadkach jest trudniejsze, ale możliwe dzięki ECN.

ECN (Explicit Coding Notation) umożliwia formalny opis niestandardowych metod
kodowania. Jest to standard ściśle związany z ASN.1 i opis danego kodowania
zawsze łączy się z pewnym opisem danych wyrażonych w ASN.1. Z tego powodu często
spotyka się określenie ASN.1+ECN.

\subsubsection{Przykład}

Prezentujemy tutaj proste przykłady użycia ASN.1 oraz ASN.1+ECN. Zostały one
pobrane z materiałów szkoleniowych dostępnych w internecie \cite{asn1-main,ecn-tutorial1,ecn-tutorial2,ecn-tutorial3}.

Poniżej definiujemy prosty protokół składający się z jednego typu PDU:
(\code{Message}). Wiadomość zbudowana jest z identyfikatora oraz jej
zawartości, będącej napisem zakodowanym w UTF-8.

\begin{textcode}
  Protocol DEFINITIONS ::= BEGIN
       Message::= SEQUENCE {
          identifier INTEGER,
          content    UTF8String
      }
  END
\end{textcode}

Taka definicja, po wybraniu kodowania, może zostać użyta do wygenerowania
odpowiednich koderów i dekoderów, aby następnie użyć jej w tworzonej aplikacji.
Dekoder zgłaszający wszelkie napotkane błędy jest doskonałym narzędziem do
przetestowania pracy innego uczestnika komunikacji (którego poprawną
implementację chcemy zweryfikować).

PDU powyższego protokołu może mieć taką postać:

\begin{textcode}
  sampleMessage Message ::= {
      identifier     3,
      content        "Hello!"
  }
\end{textcode}

Istotną cechą ASN.1 jest odseparowanie definicji danych od ich kodowania.
Dzięki temu możliwe jest zakodowanie tych samych informacji na różne sposoby. I
tak np. możemy użyć kodowania XER uzyskując poniższy XML:

\begin{xmlcode}
  <Message>
      <identifier>3</identifier>
      <content>Hello!</content>
  </FooQuestion>
\end{xmlcode}

Czasem żadne z dostępnych, uniwersalnych, kodowań nie będzie odpowiadać naszym
wymaganiom. Dzieje się tak najczęściej w przypadku protokołów sztywno
definiujących sposób kodowania informacji, jak np. wspomniany wcześniej TCP. W
takich wypadkach możemy zastosować ECN.

ECN dostarcza mechanizmów do zdefiniowania dowolnego sposobu kodowania
informacji. Załóżmy, że w PDU naszego protokołu występuje liczba przyjmująca
wartości od 0 do 7 i używamy kodowania PER. Taka liczba zostałaby zakodowana
korzystając z 3 bitów. Ze względu jednak na przewidywaną możliwość rozwoju
chcemy aby zakodowana ona była na 5 bitach. Oto jak możemy to zrobić przy
pomocy ECN.

Najpierw definicja typu w ASN.1:

\begin{textcode}
  Example-ASN1 DEFINITIONS AUTOMATIC TAGS ::=
  BEGIN
    MyType ::= INTEGER (0..7)
  END
\end{textcode}

A następnie definicja kodowania w ECN:

\begin{textcode}
  Example-EDM ENCODING-DEFINITIONS ::=
  BEGIN
  
  IMPORTS
    #MyType
  FROM Example-ASN1;
  
  MyEncodings #ENCODINGS ::= { myType-encoding }
  
  myType-encoding #MyType ::= {
    ENCODING {
      ENCODING-SPACE
      SIZE 5
      MULTIPLE OF bit
      ENCODING positive-int
    }
  }
  END
\end{textcode}

Aby tej definicji użyć potrzebny jest jeszcze moduł łączący zdefiniowane kodowanie z definicją w ASN:

\begin{textcode}
  Example-ELM LINK-DEFINITIONS ::=
  BEGIN
  
  IMPORTS
    #MyType
  FROM Example-ASN1
    MyEncodings
  FROM Example-EDM;
  
  ENCODE #MyType
    WITH          MyEncodings
    COMPLETED BY  PER-BASIC-UNALIGNED
  END
\end{textcode}

Instrukcja \code{COMPLETED BY} powoduje, że do pozostałych danych zostaną użyte
standardowe reguły kodowania PER.

Oczywiście możliwości ECN są o wiele większe i biorą pod uwagę wszystkie
spotykane w praktyce sposoby kodowania złożonych struktur, jak określanie
sposobu budowania sekwencji, wybierania typu opcji, obliczanie sum kontrolnych,
wprowadzanie wyrównań, itd.

\subsubsection{Podsumowanie}

Język ASN.1 doskonale nadaje się do tworzenia dokumentacji, z której następnie
automatycznie można generować kodery i dekodery. Dzięki temu potrzebny do
testowania parser otrzymujemy niemal zerowym kosztem.

Uważamy, że jest to jedna z technologii, która z powodzeniem może być użyta do
przeprowadzania pierwszego rodzaju testów, badających poprawność PDU.

\subsection{TTCN}
\label{ttcn}

TTCN-3 (Testing \& Test Control Notation v.~3) to język skryptowy stworzony i
rozwijany przez grupę TC-MTS (Methods for Testing and Specification Technical
Committee) w ramach ETSI \cite{ttcn-main}.

Język swoimi korzeniami (TTCN-2) sięga do lat 80 minionego wieku. Wersja 3
została zaprojektowana z myślą o tych samych zastosowaniach, korzystając z wielu
lat doświadczeń, porzucono jednak sporo archaicznych rozwiązań (wprowadzono
m.in. nową składnię). Dzisiaj TTCN to język używany od ponad 15 lat w procesach
standaryzacji i przemyśle. Użyty został np. w czasie prac nad SIP i WiMAX.

TTCN-3 najlepiej sprawdza się w testach zgodności systemów komunikacyjnych
postrzeganych jako czarne skrzynki. Nie był projektowany z myślą o testach
wydajnościowych, chociaż obecnie projektowane są rozszerzenia mające na celu
zaadresować tego typu zastosowania.

\subsubsection{System testowy TTCN-3}

Testowanie przy użyciu TTCN-3 opiera się na wykonywaniu zaimplementowanych
komponentów, które, działając w interakcji z testowanych systemem, obserwują
komunikację i zgłaszają nieprawidłowości.

Komponenty przygotowuje się korzystając z języka TTCN-3, następnie translator
generuje kod w języku ogólnego przeznaczenia, który jest kompilowany powszechnie
dostępnymi narzędziami i łączony z biblioteką TTCN. Gotowe komponenty wykonywane
są jako samodzielne programy lub interpretowane w maszynie wirtualnej TTCN-3.

Interfejsem komunikacyjnym komponentów są porty. Warstwowa budowa systemu
pozwala oddzielić implementację od docelowego systemu. Dzięki wprowadzeniu
pośrednich adapterów możliwe jest łączenie portów poszczególnych komponentów ze
sobą (aby testować sam protokół) lub portami działających węzłów, co umożliwia
np. testowanie implementacji stosu TCP/IP systemu operacyjnego.

\subsubsection{Przykład}

Załóżmy, że tworzony przez nas komponent (np. urządzenie sprzętowe) ma za
zadanie natychmiast odsyłać (echo) odbierane dane. Chcemy zweryfikować tę
cechę. Dodatkowo, ponieważ w przypadku gdy błędnie pracujący komponent w ogóle
by nie odpowiedział, czekalibyśmy w nieskończoność na wynik, wprowadzamy limit
czasowy równy jednej sekundzie.

Poniżej prezentujemy przykład zaczerpnięty z materiałów szkoleniowych
TTCN \cite{ttcn-reference}.

W teście tym definiujemy komponent \code{MainComponent} wyposażony w jeden port
komunikacyjny oraz zegar, który użyty jest do implementacji limitu czasowego.

Nasz komponent, w celu uruchomienia, wymaga środowiska systemowego. TSI (Test
System Interface) zapewnia komunikację z testowanym komponentem, w terminologii
TTCN nazywanym SUT (System Under Test). Dzięki tym dwóm konceptom możemy
połączyć naszą "wirtualną" maszynę testującą z rzeczywistym komponentem, który
chcemy testować, korzystając z mechanizmów dostarczanych przez odpowiedni
adapter oraz system operacyjny.

\begin{textcode}
  type port PortType mixed { inout all; }
  
  type component MainComponent
  {
      port PortType p;
      timer T_WAIT := 1.0;
  }
  
  type component TSI_Type
  {
      port PortType tsiPort;
  }
\end{textcode}

Obie definicje łączymy tworząc przypadek testowy:

\begin{textcode}
  testcase TC_send() runs on MainComponent system TSI_Type
  {
      map(mtc:p, system:tsiPort);
  
      p.send(10);
      T_WAIT.start;
  
      alt
      {
          [] p.receive(10)
          {
              setverdict(pass);
          }
  
          [] p.receive /* any */
          {
              setverdict(fail);
          }
  
          [] T_WAIT.timeout
          {
              setverdict(fail);
          }
      }
  }
\end{textcode}

Powyższy kod stwierdza, że test został spełniony (\code{setverdict(pass)})
jeśli na porcie \code{p} otrzymamy, wcześniej wysłaną, wartość \code{10}.
Jeżeli otrzymamy cokolwiek innego test się nie powiedzie
(\code{setverdict(fail)}).  Tak samo postępujemy, jeśli przekroczymy wcześniej
określony limit czasowy.

Tak przygotowany test tłumaczy się na kod, np. w C++, który po skompilowaniu i
linkowaniu z bibliotekami TTCN jest gotowy do uruchomienia.

Zależnie od wybranych adapterów komunikacyjnych, możemy wybrać, gdzie
faktycznie zostaną wysłane dane. Mogą to być inne urządzenia, jeśli np.
testujemy implementację protokołu działającą na routerze sprzętowym lub inny
komponent TTCN, dzięki czemu uzyskujemy możliwość tworzenia prototypowych
implementacji protokołów. Możliwości są nieograniczone ponieważ możemy
dostarczyć własny adapter komunikacyjny.

\subsubsection{Podsumowanie}

TTCN jest dojrzałym i powszechnie używanym narzędziem. Jego możliwości pozwalają
w prosty sposób, dogłębnie testować komunikację na poziomie sekwencji
komunikatów. Uważamy, że rozwiązanie to wyczerpuje problematykę związaną z
mechanizmami pracy protokołu.

Obecnie narzędzie to nie pozwala na testowanie wydajności. Przygotowywane
rozwiązania są w fazie planowania. Dodatkowo, w celu zbadania wyłącznie
wydajności, nie jest potrzebne stosowanie niskopoziomowego TTCN. Można założyć,
że komunikacja między testowanymi komponentami przebiega według ustalonych
reguł, po czym obserwować jej efektywność.

\subsection{OMNeT++}
\label{omnet}

OMNeT++ to biblioteka i framework do tworzenia symulacji sieci. Użytkownik może korzystać z
szerokiej gamy modułów oraz tworzyć własne \cite{omnet-main}. Środowisko to
wspiera symulacje sterowane zdarzeniami przesyłanymi między występującymi w
realizowanej sieci komponentami. Istnieje szereg narzędzi zbudowanych na bazie
środowiska OMNeT++, które zostały stworzone z myślą o konkretnych rodzajach
sieci, jak np. OverSim będący symulatorem sieci peer2peer.

\begin{figure}
\begin{center}
\leavevmode
\includegraphics[width=0.8\textwidth]{intro-omnet-network}
\end{center}
\caption{Wizualizacja przebiegu symulacji w sieci złożonej z sześciu węzłów.
OMNeT++ umożliwia pełną instrumentację uruchomionego modelu. Na rysunku widać
właśnie przesyłany komunikat (oznaczony czerwoną kropką).}
\label{fig:intro-omnet-network}
\end{figure}

Framework umożliwia pracę w IDE opartym na Eclipse i wspiera wiele pożądanych
funkcji jak np.~symulacje w czasie rzeczywistym czy integracja z bazą danych.
Tworzone symulacje można wykonywać jako samodzielne programy sterowane z linii
poleceń, aby zyskać na szybkości, lub pod kontrolą interfejsu graficznego
umożliwiającego dokładny wgląd w stan każdego elementu systemu.

Jest to program umożliwiający realizację i analizę prototypowych implementacji,
jak np.~algorytmów routingu. Nie został zaprojektowany z myślą o symulacji
złożonych systemów, takich jak pełna implementacja stosu sieciowego w systemie
operacyjnym. Tego typu realizacje są możliwe, ale działają niewydajnie.

\subsubsection{Przykład}

Pełna konfiguracja testu dla środowiska OMNeT++ jest zbyt złożona, żeby ją tu w
całości przytaczać. Prezentujemy tylko wybrane fragmenty, bazując na
materiałach szkoleniowych dostępnych w \cite{omnet-doc}.

Podstawowe moduły, tj. takie, których działanie programuje użytkownik,
definiowane są dyrektywą \code{simple}. Poniżej przykład komponentu o nazwie
\code{EtherMAC}. Zawiera on parametr \code{address}, którego wartość można
podać uruchamiając test lub zapisać w pliku konfiguracyjnym. Zdefiniowane są
także porty służące do komunikacji z innymi modułami. W tym wypadku warstwą LLC
oraz łącza danych.

\begin{textcode}
  simple EtherMAC {
      parameters:
          string address;
      gates:
          input phyIn;
          output phyOut;
          input llcIn;
          output llcOut;
  }
\end{textcode}

Komponenty typu \code{simple} można składać tworząc większe moduły, których
zadaniem jest organizacja podstawowych komponentów i definiowanie połączeń
między nimi.

Poniższy kod pokazuje jak z komponentów \code{EtherTrafficGen}, \code{EtherLLC}
oraz \code{EtherMAC} tworzony jest moduł \code{EtherStation}.

\begin{textcode}
  module EtherStation {
      parameters: ...
      gates: ...
          input in;
          output out;  
      submodules:
          app: EtherTrafficGen;
          llc: EtherLLC;
          mac: EtherMAC;
      connections:
          app.out --> llc.hlIn;
          app.in <-- llc.hlOut;
          llc.macIn <-- mac.llcOut;
          llc.macOout --> mac.llcIn;
          mac.phyIn <-- in;
          mac.phyOut --> out;
  }
\end{textcode}

Aby przykład był kompletny, należałoby jeszcze zdefiniować sieć i jej
topologię.  Powyższy moduł zawiera definicje dwóch portów (sekcja
\code{gates}), które mają posłużyć właśnie połączeniu z innymi komponentami
(np. modelującymi hub). Dodatkowo całość potrzebuje konfiguracji
uruchomieniowej. Graficzne środowisko ułatwia tworzenie tych brakujących elementów.

\begin{figure}
\begin{center}
\leavevmode
\includegraphics[width=0.8\textwidth]{intro-omnet-histogram}
\end{center}
\caption{OMNeT++ zawiera narzędzia ułatwiające gromadzenie
danych statystycznych oraz graficzną analizę wyników. Na rysunku widać
przykładowy histogram uzyskany po wykonaniu testu.}
\label{fig:intro-omnet-histogram}
\end{figure}

\subsubsection{Podsumowanie}

OMNeT++ to rozbudowane środowisko umożliwiające tworzenie testów modelujących
złożone systemy. Pracę wspiera graficzny interfejs oraz framework
udostępniający szeroką gamę najczęściej potrzebnych funkcji.

Pewną wadą jest niska wydajność w sytuacji, gdy modeluje się systemy z dużą
liczbą komponentów intensywnie się komunikujących.

\subsection{Podsumowanie}

Przeprowadzenie testu w środowisku rozproszonym dostarcza nowego rodzaju
trudności związanych z koniecznością obsługi wielu urządzeń. Dostępne
rozwiązania najczęściej tworzone są z myślą o testowaniu w warunkach
symulacyjnych, gdzie całą sieć odtwarzamy na pojedynczym komputerze. Tego typu
testy są pomocne, jednak nie wyczerpują całego spektrum zastosowań.

Środowisko rzeczywistej sieci zachowuje się inaczej niż symulator. Zarówno ze
względu na cechy fizyczne, jak też realne rozproszenie maszyn, a co za tym
idzie inny sposób dostępu do nich. Trzeba też pamiętać, że aplikacje często
osiągają inne wyniki, kiedy pracują w realnej sieci i komunikują się między
sobą, a nie z symulatorem.

Nie dotarliśmy do programu, który ułatwiałby wykonanie testów w
rzeczywistych sieciach, gdzie problemy takie jak synchronizacja urządzeń i
zbieranie wyników powodują, że ręczne wykonywanie wszystkich czynności staje
się bardzo czasochłonne i uciążliwe, choć sam test jest w swojej naturze prosty.

W tabeli poniżej porównujemy naszym zdaniem najistotniejsze cechy wspomnianych
narzędzi. Mówiąc o deterministycznych wynikach mamy na myśli wyniki, które będą
identyczne po każdym wykonaniu testu. Przez brak wpływu na wydajność rozumiemy
bezpośrednie wykonywanie testowanego systemu w jego naturalnym środowisku, np.
bezpośrednio pod kontrolą systemu operacyjnego.

\begin{small}
\begin{center}
   \begin{tabular}{ l || C{1.6cm} | C{1.6cm} | C{1.6cm} | C{1.6cm}   }
      \hline
      & \small{\parbox[top][3.4em][c]{1.6cm}{\centering{ASN.1+\\ECN}}} & \small{TTCN} & \small{OMNeT} & \small{Arete} \\
      \hline
      Powtarzanie eksperymentów & $+$ & $+$ & $+$ & $+$ \\
      \hline
      Deterministyczne wyniki & $+$ & $+$ & $+$ & $-$ \\
      \hline
      Weryfikacja wyników & $+$ & $+$ & $-$ & $-$ \\
      \hline
      Brak izolacji wpływu środowiska & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Wykorzystanie rzeczywistych urządzeń & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Testy wymienianych PDU & $+$ & $+$ & $+$ & $-$ \\
      \hline
      Testy sekwencji komunikatów & $-/+$ & $+$ & $+$ & $-/+$ \\
      \hline
      Testy wydajnościowe & $-$ & $+$ & $-$ & $+$ \\
      \hline
      Brak wpływu na wydajność & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Możliwość rozwijania narzędzia & $-$ & $-/+$ & $+$ & $+$ \\
      \hline
      Dostępne darmowo & $-/+$ & $-$ & $-/+$ & $+$ \\
      \hline
      Łatwość nauki & $-$ &  $+$ & $+$ & $+$ \\
      \hline

  \end{tabular}
\end{center}
\end{small}

Jak widać Arete nie jest idealnym narzędzie do każdego typu zastosowań. Nie
jest to również narzędzie zdolne do samodzielnej pracy.  Uważamy jednak, że
dobrze uzupełnia funkcjonalne braki istniejących rozwiązań i razem z nimi
pozwala stworzyć praktyczne i wygodne środowisko testowe.

\section{Krytyka}

Zamykając ten rozdział pragniemy przytoczyć kilka krytycznych opinii
dotyczących automatyzacji testów i ustosunkować się do nich jako twórcy jednego
z rozwiązań.

W czasie pracy mieliśmy na uwadzę tezę jakoby współczesne społeczeństwo
informatyczne nie dostrzegało pułapek i trudności procesu automatyzacji testów.
Nie wdając się w dyskusję czy jest to teza prawdziwa, podeszliśmy do
zagadnienia z ostrożnością. Pozwoliło nam to wykreślić z wymagań pewne ambitne,
ale mało realne i tylko sporadycznie potrzebne funkcje.

Istotny zarzut stawiany w \cite{snake-oil} dotyczy postrzegania przypadku
testowego jako sekwencji akcji do wykonania, podczas gdy bardziej praktyczne
ujęcie zagadnienia powinno być sekwencją interakcji przeplecionych z
wykonywaniem testu. W takim ujęciu osoba przeprowadzająca złożony test jest
częścią interakcji między testowanym systemem a jego środowiskiem. Ma ona także
możliwość na bieżąco zmieniać plan testu. Zgadzamy się, że w pewnych wypadkach
taka interakcja daje możliwość tworzenia bardziej interesujących przypadków
testowych. 

Z drugiej strony w obronie możemy przytoczyć kolejny punkt krytyki: próba
automatyzacji wszystkich potrzebnych testów prawdopodobnie będzie wymagać o
wiele więcej środków a skończy się stworzeniem słabych testów, które przeoczą
wiele problemów a znajdą wiele sytuacji, w których problem okaże się poprawnym,
chociaż nieoczekiwanym, zachowaniem.

Naszym zdaniem lepszą decyzją jest pozostanie przy prostej funkcjonalności,
która sprawdza się tam, gdzie automatyzacja daje najlepsze rezultaty, niż
rozbudowywanie narzędzia umożliwiając jego użycie w przypadkach, których sens
automatyzacji pozostaje wątpliwy.

Wszystkie automatyzowane testy wymagają interwencji człowieka. W idealnym
wypadku ogranicza się ona do analizy wyników, ale też naprawy złych przypadków
testowych. Trzeba pamiętać, że nie łatwo jest stworzyć złożony zestaw testów
bez żadnych błędów. Nawet jeśli nie ma ich w pierwotnej wersji, wraz z rozwojem
testowanego systemu testy często trzeba zmieniać.

Jeśli więc człowiek jest obecny także w procesie automatycznego testowania, nie
powinien on przekazywać maszynie wykonywania tych czynności, które jest w
stanie zrobić lepiej.

Nie możemy zaprzeczyć powyższym postulatom. Trafnie uderzają one w słabe punkty
automatyzacji. Mając jednak na uwadze przewidziany przez nas obszar zastosowań,
uważamy, że storzone przez nas narzędzie dobrze spełnia swoją rolę.

\end{document}
