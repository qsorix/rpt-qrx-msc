\documentclass[00-praca-magisterska.tex]{subfiles}

\begin{document}

\chapter{Testowanie}

Inżynieria oprogramowania bardzo szeroko omawia tematykę testów, na każdym
kroku podkreślając wagę i nieodłączność tej fazy w procesie tworzenia
oprogramowania.  Powstający produkt testuje się, aby zapewnić jak najwyższą
jakość dostarczanego oprogramowania. Pod tym ogólnym stwierdzeniem często
rozumie się co innego, w zależności od rodzaju i przeznaczenia programu.
Dlatego też w tym rozdziale przybliżamy zakres zagadnień, na którym skupimy się
w pracy.

\section{Dlaczego testujemy}

Oprogramowanie testuje się, żeby sprawdzić zgodność jego działania ze specyfikacją. Twórcy
zależy na tym, żeby zminimalizować liczbę swoich błędów. Odbiorca natomiast
chciałby potwierdzenia, że otrzymuje produkt, jakiego oczekiwał. Pod tymi
słowami kryje się za każdym razem inny konkret, któremu się przyglądamy, jednak
kilka ogólnych cech pozostaje niezmiennych.

Pierwszą taką cechą jest weryfikacja mierzalnej wartości. Testy powstają w celu
sprawdzenia czy otrzymane wyniki spełniają określone kryteria. Wymagane jest
więc określenie jakich wartości oczekujemy od poszczególnych czynników. Biorąc
za przykład popularny ostatnio ,,szybki Internet'' łatwo pokazać, że samo
nazwanie czegoś szybkim nie przedstawia żadnej cennej informacji, gdyż mówiąc
potocznie, dostawcy usług zawsze dostarczają najszybszy Internet, a mimo to z
roku na rok udaje się zapewnić jeszcze szybsze łącza. 

Obiektywne sformułowanie przedmiotu testu wymienia nie tylko badaną wielkość,
ale również oczekiwaną wartość. Mówienie o szybkości transferu ma sens, kiedy
padają konkretne liczby, ponieważ wtedy można je porównać z przewidywaniami i
stwierdzić czy dana szybkość nas zadowala. Może zdarzyć się, że taka wartość
odniesienia nie istnieje. Przy pierwszym pomiarze czasu wykonania nowego
algorytmu możemy tylko zgadywać lub subiektywnie oceniać go w świetle podobnych
algorytmów. W kolejnych pomiarach dysponujemy już jednak poprzednią wartością i
możemy wnioskować z jej pomocą. Niezmienny jest jednak fakt, że sprawdzamy
wielkość, którą można zmierzyć i nasze pomiary nie są zaburzone naszą osobistą
oceną.

Możliwość dokonania kolejnego pomiaru jest drugą bardzo istotną cechą testu.
Dzięki temu jesteśmy w stanie ocenić jak na wyniki wpływają takie czynniki jak
sprzęt czy zmiany w oprogramowaniu. Istnieje szereg testów, których charakter
uniemożliwia ich powtórzenie lub czyni je kosztownym. Na szczęście sprzęt
sieciowy nie ulega zniszczeniu w czasie większości testów. Uruchomienie tego
samego testu na różnego rodzaju urządzeniach pozwala stwierdzić czy tworzone
rozwiązanie jest przenośne, czy się skaluje, czy sprawdza się w specyficznych
warunkach itp. W zastosowaniach związanych z sieciami komputerowymi tego typu
testy są szczególnie istotne ze względu na różnorodność dostępnych urządzeń i
protokołów.

Tworzenie, poprawianie i rozbudowywanie oprogramowania wiąże się nieodłącznie
ze zmianami w kodzie. Możliwość wielokrotnego testowania danej funkcjonalności
pozwala ocenić ją w świetle wprowadzanych zmian. Najpierw można przekonać się o
tym, że pożądana cecha została osiągnięta. Następnie, w przypadku poprawek
istniejącego produktu, możemy przekonać się, że problemy zostały usunięte, a
także, że ich eliminacja nie zaburzyła innych komponentów. To samo dotyczy nowo
dodanych funkcjonalności. Mamy również możliwość oceny wpływu zmian na
wydajność i to przy systematycznym wykonywaniu testów na przestrzeni życia
całego projektu.

\FIXME{Podsumować jakoś to testowanie...}

Testowanie jest zatem bardzo istotnym i nieodłącznym elementem tworzenia oprogramowania...

\section{Testy aplikacji sieciowych}

W sieciach komputerowych oprogramowanie wykorzystuje się na różnych warstwach
modelu OSI powierzając mu różne zadania i inaczej je implementujec. Od każdego
składnika sieciowego stosu oczekujemy poprawnej pracy, którą można weryfikować
testami. Inaczej wyglądają testy protokołu CSMA/CD, inaczej protokołu TCP,
wreszcie zupełnie inne są testy aplikacji synchronizującej kalendarz z
urządzeniem mobilnym. Z drugiej strony często można znaleźć elementy wspólne
pomimo tego, że badane implementacje realizują zupełnie inną funkcjonalność.

W dalszych rozważaniach skupimy się na podziale testów ze względu na rodzaj
obserwowanych wielkości, ponieważ niezależnie od warstwy, sposób ich pomiaru
jest podobny. Wyróżniliśmy następujące rodzaje testów:
\begin{itemize}
  \item wymienianych PDU,
  \item sekwencji komunikatów,
  \item wydajności transmisji.
\end{itemize}

Pierwszy rodzaj dotyczy poprawności budowy komunikatów wymienianych między
urządzeniami. Są to testy mające na celu sprawdzić czy przesyłane dane
odpowiadają założeniom.  Badane są takie wielkości jak: długość PDU, zgodność
sumy kontrolnej, poprawność kodowania numeru wersji itp. Kontrola jakości na
tym etapie ma na celu zweryfikowanie, czy wygenerowane bity reprezentują PDU
zgodne ze specyfikacją. Od wykorzystywanych tu narzędzi wymaga się, aby
umożliwiały sformalizowanie opisu zawartego w dokumentacji do postaci, którą
można algorytmicznie porównać z obserwowanymi PDU.

Kiedy operujemy poprawnymi komunikatami, należy zadbać o poprawność ich
sekwencji. Skuteczna komunikacja najczęściej wymaga zachowania pewnej
kolejności i rodzaju przesyłanych PDU. Testy sprawdzają czy obserwowane grupy
komunikatów odpowiadają tym ze specyfikacji, np. czy numery potwierdzeń
odpowiadają numerom wysyłanych danych, czy na generowane zapytania otrzymujemy
odpowiedzi, czy komponent poprawnie reaguje na utracone lub przekłamane dane
itd. Od narzędzi wymaga się już nie tylko parsowania PDU, ale też
interpretowania ich zawartości i podążania za obserwowanym, globalnym stanem
połączenia.

Wydajność transmisji dotyczy między innymi osiąganych przepustowości, reakcji
na zatory, rywalizacji z innymi przepływami, jakości łączy fizycznych i innych
czynników mających wpływ na odczuwalną jakość połączenia. Chociaż wystarczą tu
najprostsze narzędzia (niemal każdy klient HTTP jest w stanie wyświetlić
uzyskaną przepływność), jest to najtrudniejsza płaszczyzna testów. O ile w
przypadku obserwacji pojedynczych PDU i ich sekwencji większość testów można
automatycznie wygenerować z dokumentacji protokołu, to zbadanie kwestii
wydajności jest bardzo trudne bez udziału człowieka.

W tego typu testach sama implementacja odgrywa istotną rolę, ale ogromne
znaczenie ma też wpływ środowiska i to użytkownik musi zadecydować o tym, jakie
warunki chcemy badać, bo tylko on zna przeznaczenie tworzonego oprogramowania.
Test w tym przypadku nie polega na zatwierdzeniu lub odrzuceniu pojedynczego
przypadku, a na analizie wielokrotnie powtarzanych eksperymentów i odniesieniu
wyników do teoretycznych założeń. Wiedza ekspercka jest tu nieodzowna.
Narzędzia do testowania wydajności nie powinny więc wyręczać człowieka, ale
wspierać go ułatwiając konfigurację środowiska, obsługę wielu urządzeń
jednocześnie i katalogowanie wyników.

\section{Testy w warunkach rzeczywistych, a symulacje}

Jest jasne, że eksperymenty najwygodniej przeprowadza się w sterylnych
warunkach laboratorium. Błędem jest jednak oczekiwanie, że produkt będzie
zachowywał się identycznie w normalnym użytkowaniu, a inżynieria oprogramowania
zaleca nawet wykonywanie testowej instalacji wdrożeniowej, aby zaobserwować
powstające różnice. Testy wykonywane w warunkach rzeczywistych mają zarówno
wady jak i zalety.  Wracając do omówionych powyżej rodzajów testów, można
powiedzieć, że w zależności od testu pożądane będą różne warunki jego
wykonania.

Aby sprawdzić czy algorytm generuje poprawne PDU najwygodniej jest skorzystać
ze środowiska testowego, debuggera czy symulatora. Opóźnienia związane z realną
transmisją są niepotrzebne, a nawet nieporządane. Możemy nawet uruchomić
algorytm osobno, poza stosem sieciowym, i analizować jego działanie
niezależnie. W przypadku sekwencji komunikatów również wystarczy symulowanie
uczestników komunikacji, gdyż zakładając poprawne działanie pozostałych
elementów sieci, skupimy się w ten sposób na danym algorytmie.

Test w warunkach rzeczywistych zawsze będzie wartościowym uzupełnieniem,
ponieważ na symulatorze możemy zapomnieć o takich problemach jak przekłamania
bitów czy gubienie PDU, a tworzone oprogramowanie powinno być na te zjawiska
odporne. Najlepszym scenariuszem byłoby testowanie dwóch powyższych
jednocześnie z wydajnością, ale jednoczesna analiza może prowadzić do
otrzymania złych wyników. Wydajność może być niższa od rzeczywistej z powodu
narzutu związanego ze sprawdzaniem komunikacji.

Pomiar wydajności w warunkach symulowanych dostarcza cennych informacji na
temat wymagań stawianych procesorowi czy pamięci. Trzeba mieć jednak na uwadze,
że otrzymywane wyniki mają szczególny charakter i nie należy ich przekładać na
oczekiwane zachowania w rzeczywistych sieciach. Dostępna obecnie moc
obliczeniowa pozwala symulować wiele czynników występujących w prawdziwych
sieciach, można więc coraz więcej testów przeprowadzać w środowiskach
wirtualnych. Uważamy jednak, że mnogość czynników, które trzeba uwzględnić,
wciąż przemawia na korzyść testów w warunkach rzeczywistych. Te czynniki to
między innymi:
\begin{itemize}
\item zawodność sprzętu,
\item wpływ innych użytkowników,
\item opóźnienia,
\item problem synchronizacji,
\item kwestie bezpieczeństwa.
\end{itemize}

Mimo, że powinno się myśleć o tych problemach jak o przeszkodach, to właśnie
fakt ich występowania jest powodem, dla którego test przeprowadzamy. Zjawiska
te, z natury nieprzewidywalne, uderzają w założenia o powtarzalności testu. Z
tego powodu należy monitorować i w miarę możliwości odnotowywać ich wpływ, aby
w zebranych wynikach móc poszukiwać relacji tłumaczących ewentualne zmiany w
obserwowanym zachowaniu. Trzeba też pamiętać, że zbierane wyniki nabierają
charakteru statystycznego i aby stały się wiarygodne, testy należy wielokrotnie
powtarzać.

\section{Dostępne rozwiązania}

\FIXME{Przykłady użycia tych rozwiązań. Zilustrowanie kodem i jakimiś
screenshotami. Ogólnie to więcej obrazków ma być.}

Istnieje wiele programów rozwiązujących problem automatyzacji testowania, które
w różnym stopniu i na różnych poziomach pozwalają na ułatwienie i przyspieszenie
przeprowadzania testów aplikacji i protokołów sieciowych. Jednak spośród znanych
nam rozwiązań, żadne nie pozwalało przeprowadzić takiego rodzaju testów, jakie
próbowaliśmy wykonać.

\subsection{ASN.1 i ECN}
ASN.1 (Abstract Syntax Notation One) jest to standard ITU-T/ISO służący do opisu
struktur reprezentujących dane w sposób umożliwiający ich kodowanie, transmisję
i dekodowanie. Dostarcza on formalnej notacji do opisu struktur w sposób
niezwiązany z reprezentacją sprzętową.

ASN.1 definiuje sposób opisu danych. Jest on niezależny od metod ich kodowania,
przedstawionych w oddzielnych dokumentach. Przykładowe metody to:
\begin{itemize}
\item BER (Basic Encoding Rules),
\item PER (Packed Encoding Rules),
\item XER (XML Encoding Rules).
\end{itemize}

Wykorzystanie formalnych metod opisu pozwala na automatyczne tworzenie koderów i
dekoderów. W przypadku pracy z istniejącymi protokołami, PDU zwykle na stałe
wiąże przenoszone dane z ich kodowaniem. Przykładem może być opis pakietów TCP w
RFC 793, gdzie dane (np. numer sekwencyjny) i ich kodowanie (rozmiar i
położenie bitów w pakiecie) określone są w tym samym miejscu. Nie ma więc podziału między semantyką informacji i jej bitową reprezentacją. Korzystanie z ASN.1 w takich wypadkach jest
trudniejsze, ale możliwe dzięki ECN.

ECN (Explicit Coding Notation) umożliwia formalny opis niestandardowych metod
kodowania. Jest to standard ściśle związany z ASN.1 i opis danego kodowania
zawsze łączy się z pewnym opisem danych wyrażonych w ASN.1. Z tego powodu często
spotyka się określenie ASN.1+ECN.

\subsubsection{Przykład użycia}

\FIXME{Przykład użycia...}

\subsubsection{Podsumowanie}

Język ASN.1 doskonale nadaje się do tworzenia dokumentacji, z której następnie
automatycznie można generować kodery i dekodery. Dzięki temu potrzebny do
testowania parser otrzymujemy niemal zerowym kosztem.

Uważamy, że jest to jedna z technologii, która z powodzeniem może być użyta do
przeprowadzania pierwszego rodzaju testów, badających poprawność PDU.

\subsection{TTCN}

TTCN-3 (Testing \& Test Control Notation v.~3) to język skryptowy stworzony i
rozwijany przez grupę TC-MTS (Methods for Testing and Specification Technical
Committee) w ramach ETSI.

Język swoimi korzeniami (TTCN-2) sięga do lat 80 minionego wieku. Wersja 3
została zaprojektowana z myślą o tych samych zastosowaniach, korzystając z wielu
lat doświadczeń, porzucono jednak sporo archaicznych rozwiązań (wprowadzono
m.in. nową składnię). Dzisiaj TTCN to język używany od ponad 15 lat w procesach
standaryzacji i przemyśle. Użyty został np. w czasie prac nad SIP i WiMAX.

TTCN-3 najlepiej sprawdza się w testach zgodności systemów komunikacyjnych
postrzeganych jako czarne skrzynki. Nie był projektowany z myślą o testach
wydajnościowych, chociaż obecnie projektowane są rozszerzenia mające na celu
zaadresować tego typu zastosowania.

\subsubsection{System testowy TTCN-3}

Testowanie przy użyciu TTCN-3 opiera się na wykonywaniu zaimplementowanych
komponentów, które, działając w interakcji z testowanych systemem, obserwują
komunikację i zgłaszają nieprawidłowości.

Komponenty przygotowuje się korzystając z języka TTCN-3, następnie translator
generuje kod w języku ogólnego przeznaczenia, który jest kompilowany powszechnie
dostępnymi narzędziami i łączony z biblioteką TTCN. Gotowe komponenty wykonywane
są jako samodzielne programy lub interpretowane w maszynie wirtualnej TTCN-3.

Interfejsem komunikacyjnym komponentów są porty. Warstwowa budowa systemu
pozwala oddzielić implementację od docelowego systemu. Dzięki wprowadzeniu
pośrednich adapterów możliwe jest łączenie portów poszczególnych komponentów ze
sobą (aby testować sam protokół) lub portami działających węzłów, co umożliwia
np. testowanie implementacji stosu TCP/IP systemu operacyjnego.

\subsubsection{Przykład użycia}

\FIXME{Przykład użycia...}

\subsubsection{Podsumowanie}

TTCN jest dojrzałym i powszechnie używanym narzędziem. Jego możliwości pozwalają
w prosty sposób, dogłębnie testować komunikację na poziomie sekwencji
komunikatów. Uważamy, że rozwiązanie to wyczerpuje problematykę związaną z
mechanizmami pracy protokołu.

Obecnie narzędzie to nie pozwala na testowanie wydajności. Przygotowywane
rozwiązania są w fazie planowania. Dodatkowo, w celu zbadania wyłącznie
wydajności, nie jest potrzebne stosowanie niskopoziomowego TTCN. Można założyć,
że komunikacja między testowanymi komponentami przebiega według ustalonych
reguł, po czym obserwować jej efektywność.

\subsection{OMNeT++}

OMNeT++ to biblioteka i framework do tworzenia symulacji sieci. Użytkownik może korzystać z
szerokiej gamy modułów oraz tworzyć własne. Środowisko to wspiera symulacje
sterowane zdarzeniami przesyłanymi między występującymi w realizowanej sieci
komponentami. Istnieje szereg narzędzi zbudowanych na bazie środowiska OMNeT++,
które zostały stworzone z myślą o konkretnych rodzajach sieci, jak np. OverSim
będący symulatorem sieci peer2peer.

Framework umożliwia pracę w IDE opartym na Eclipse i wspiera wiele pożądanych
funkcji jak np.~symulacje w czasie rzeczywistych czy integracja z bazą danych.
Tworzone symulacje można wykonywać jako samodzielne programy sterowane linią
polecenia, aby zyskać na szybkości, lub pod kontrolą interfejsu graficznego
umożliwiającego dokładny wgląd w stan każdego elementu systemu.

Jest to program umożliwiający realizację i analizę prototypowych implementacji,
jak np.~algorytmów routingu. Nie został zaprojektowany z myślą o symulacji
złożonych systemów, takich jak pełna implementacja stosu sieciowego w systemie
operacyjnym. Tego typu realizacje są możliwe, ale działają niewydajnie.

\FIXME{Chociaż istnieje możliwość uruchomienia symulacji na kilku urządzeniach
jednocześnie, wykonywany kod pozostaje pod kontrolą środowiska OMNeT++.

\emph{Wyjaśnić dlaczego, bo nie jest to jasne.}

Nie jest możliwy przypadek użycia, w którym za pomocą OMNeT++ sterujemy pracą
zdalnych systemów, wykonując na nich własną aplikację.}

\subsubsection{Przykład użycia}

\FIXME{Przykład użycia...}

\subsection{Podsumowanie}

Przeprowadzenie testu w środowisku rozproszonym dostarcza nowego rodzaju
trudności związanych z koniecznością obsługi wielu urządzeń. Dostępne
rozwiązania najczęściej tworzone są z myślą o testowaniu w warunkach
symulacyjnych, gdzie całą sieć odtwarzamy na pojedynczym komputerze. Tego typu
testy są pomocne, jednak nie wyczerpują całego spektrum zastosowań.

Środowisko rzeczywistej sieci zachowuje się inaczej niż symulator. Zarówno ze
względu na cechy fizyczne, jak też realne rozproszenie maszyn, a co za tym
idzie inny sposób dostępu do nich. Trzeba też pamiętać, że aplikacje często
osiągają inne wyniki, kiedy pracują w realnej sieci i komunikują się między
sobą, a nie z symulatorem.

Nie dotarliśmy do programu, który ułatwiałby wykonanie testów w
rzeczywistych sieciach, gdzie problemy takie jak synchronizacja urządzeń i
zbieranie wyników powodują, że ręczne wykonywanie wszystkich czynności staje
się bardzo czasochłonne i uciążliwe, choć sam test jest w swojej naturze prosty.

W tabeli \fixref{tej poniżej} porównujemy naszym zdaniem najistotniejsze cechy
wspomnianych narzędzi. Jak widać Arete nie jest idealnym narzędzie do każdego
typu zastosowań. Nie jest to również narzędzie zdolne do samodzielnej pracy.
Uważamy jednak, że dobrze uzupełnia funkcjonalne braki istniejących rozwiązań i
razem z nimi pozwala stworzyć praktyczne i wygodne środowisko testowe.

\begin{small}
\begin{center}
   \begin{tabular}{ l || C{1.1cm} | C{1.1cm} | C{1.1cm} | C{1.1cm}   }
      \hline
      & \small{\parbox[top][2.4em][c]{1.1cm}{\centering{ASN.1+\\ECN}}} & \small{TTCN} & \small{OMNeT} & \small{Arete} \\
      \hline
      Powtarzanie eksperymentów & $+$ & $+$ & $+$ & $+$ \\
      \hline
      Deterministyczne wyniki & $+$ & $+$ & $+$ & $-$ \\
      \hline
      Weryfikacja wyników & $+$ & $+$ & $-$ & $-$ \\
      \hline
      Uwzględnienie wpływu środowiska & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Wykorzystanie rzeczywistych urządzeń & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Testy wymienianych PDU & $+$ & $+$ & $+$ & $-$ \\
      \hline
      Testy sekwencji komunikatów & $-/+$ & $+$ & $+$ & $-/+$ \\
      \hline
      Testy wydajnościowe & $-$ & $+$ & $-$ & $+$ \\
      \hline
      Brak wpływu na wydajność & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Możliwość rozwijania narzędzia & $-$ & $-/+$ & $+$ & $+$ \\
      \hline
      Dostępne darmowo & $-/+$ & $-$ & $-/+$ & $+$ \\
      \hline
      Łatwość nauki & $-$ &  $+$ & $+$ & $+$ \\
      \hline

  \end{tabular}
\end{center}
\end{small}

\end{document}
