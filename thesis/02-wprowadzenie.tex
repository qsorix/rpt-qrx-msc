\documentclass[00-praca-magisterska.tex]{subfiles}

\begin{document}

\chapter{Testowanie}

Inżynieria oprogramowania bardzo szeroko omawia tematykę testów, na każdym
kroku podkreślając wagę i nieodłączność tej fazy w procesie tworzenia
oprogramowania.  Powstający produkt testuje się, aby zapewnić jak najwyższą
jakość dostarczanego oprogramowania. Pod tym ogólnym stwierdzeniem często
rozumie się co innego, w zależności od rodzaju i przeznaczenia programu.
Dlatego też w tym rozdziale przybliżamy zakres zagadnień, na którym skupimy się
w pracy.

\section{Dlaczego testujemy}

Oprogramowanie testuje się, żeby sprawdzić zgodność jego działania ze specyfikacją. Twórcy
zależy na tym, żeby zminimalizować liczbę swoich błędów. Odbiorca natomiast
chciałby potwierdzenia, że otrzymuje produkt, jakiego oczekiwał. Pod tymi
słowami kryje się za każdym razem inny konkret, któremu się przyglądamy, jednak
kilka ogólnych cech pozostaje niezmiennych.

Pierwszą taką cechą jest weryfikacja mierzalnej wartości. Testy powstają w celu
sprawdzenia czy otrzymane wyniki spełniają określone kryteria. Wymagane jest
więc określenie jakich wartości oczekujemy od poszczególnych czynników. Biorąc
za przykład popularny ostatnio ,,szybki Internet'' łatwo pokazać, że samo
nazwanie czegoś szybkim nie przedstawia żadnej cennej informacji, gdyż mówiąc
potocznie, dostawcy usług zawsze dostarczają najszybszy Internet, a mimo to z
roku na rok udaje się zapewnić jeszcze szybsze łącza. 

Obiektywne sformułowanie przedmiotu testu wymienia nie tylko badaną wielkość,
ale również oczekiwaną wartość. Mówienie o szybkości transferu ma sens, kiedy
padają konkretne liczby, ponieważ wtedy można je porównać z przewidywaniami i
stwierdzić czy dana szybkość nas zadowala. Może zdarzyć się, że taka wartość
odniesienia nie istnieje. Przy pierwszym pomiarze czasu wykonania nowego
algorytmu możemy tylko zgadywać lub subiektywnie oceniać go w świetle podobnych
algorytmów. W kolejnych pomiarach dysponujemy już jednak poprzednią wartością i
możemy wnioskować z jej pomocą. Niezmienny jest jednak fakt, że sprawdzamy
wielkość, którą można zmierzyć i nasze pomiary nie są zaburzone naszą osobistą
oceną.

Możliwość dokonania kolejnego pomiaru jest drugą bardzo istotną cechą testu.
Dzięki temu jesteśmy w stanie ocenić jak na wyniki wpływają takie czynniki jak
sprzęt czy zmiany w oprogramowaniu. Istnieje szereg testów, których charakter
uniemożliwia ich powtórzenie lub czyni je kosztownym. Na szczęście sprzęt
sieciowy nie ulega zniszczeniu w czasie większości testów. Uruchomienie tego
samego testu na różnego rodzaju urządzeniach pozwala stwierdzić czy tworzone
rozwiązanie jest przenośne, czy się skaluje, czy sprawdza się w specyficznych
warunkach itp. W zastosowaniach związanych z sieciami komputerowymi tego typu
testy są szczególnie istotne ze względu na różnorodność dostępnych urządzeń i
protokołów.

Tworzenie, poprawianie i rozbudowywanie oprogramowania wiąże się nieodłącznie
ze zmianami w kodzie. Możliwość wielokrotnego testowania danej funkcjonalności
pozwala ocenić ją w świetle wprowadzanych zmian. Najpierw można przekonać się o
tym, że pożądana cecha została osiągnięta. Następnie, w przypadku poprawek
istniejącego produktu, możemy przekonać się, że problemy zostały usunięte, a
także, że ich eliminacja nie zaburzyła innych komponentów. To samo dotyczy nowo
dodanych funkcjonalności. Mamy również możliwość oceny wpływu zmian na
wydajność i to przy systematycznym wykonywaniu testów na przestrzeni życia
całego projektu.

Testowanie jest więc bardzo istotnym elementem procesu tworzenia
oprogramowania. Żeby testy były przydatne, należy zadbać aby obserwowane cechy
były mierzalne i posiadały obiektywną wartość odniesienia. Test musi też być
powtarzalny, a jego poprzednie wyniki dostępne dla porównania z bieżącymi.

\section{Testy aplikacji sieciowych}

W sieciach komputerowych oprogramowanie wykorzystuje się na różnych warstwach
modelu OSI powierzając mu różne zadania i inaczej je implementujec. Od każdego
składnika sieciowego stosu oczekujemy poprawnej pracy, którą można weryfikować
testami. Inaczej wyglądają testy protokołu CSMA/CD, inaczej protokołu TCP,
wreszcie zupełnie inne są testy aplikacji synchronizującej kalendarz z
urządzeniem mobilnym. Z drugiej strony często można znaleźć elementy wspólne
pomimo tego, że badane implementacje realizują zupełnie inną funkcjonalność.

W dalszych rozważaniach skupimy się na podziale testów ze względu na rodzaj
obserwowanych wielkości, ponieważ niezależnie od warstwy, sposób ich pomiaru
jest podobny. Wyróżniliśmy następujące rodzaje testów:
\begin{itemize}
  \item wymienianych PDU,
  \item sekwencji komunikatów,
  \item wydajności transmisji.
\end{itemize}

Pierwszy rodzaj dotyczy poprawności budowy komunikatów wymienianych między
urządzeniami. Są to testy mające na celu sprawdzić czy przesyłane dane
odpowiadają założeniom.  Badane są takie wielkości jak: długość PDU, zgodność
sumy kontrolnej, poprawność kodowania numeru wersji itp. Kontrola jakości na
tym etapie ma na celu zweryfikowanie, czy wygenerowane bity reprezentują PDU
zgodne ze specyfikacją. Od wykorzystywanych tu narzędzi wymaga się, aby
umożliwiały sformalizowanie opisu zawartego w dokumentacji do postaci, którą
można algorytmicznie porównać z obserwowanymi PDU.

Kiedy operujemy poprawnymi komunikatami, należy zadbać o poprawność ich
sekwencji. Skuteczna komunikacja najczęściej wymaga zachowania pewnej
kolejności i rodzaju przesyłanych PDU. Testy sprawdzają czy obserwowane grupy
komunikatów odpowiadają tym ze specyfikacji, np. czy numery potwierdzeń
odpowiadają numerom wysyłanych danych, czy na generowane zapytania otrzymujemy
odpowiedzi, czy komponent poprawnie reaguje na utracone lub przekłamane dane
itd. Od narzędzi wymaga się już nie tylko parsowania PDU, ale też
interpretowania ich zawartości i podążania za obserwowanym, globalnym stanem
połączenia.

Wydajność transmisji dotyczy między innymi osiąganych przepustowości, reakcji
na zatory, rywalizacji z innymi przepływami, jakości łączy fizycznych i innych
czynników mających wpływ na odczuwalną jakość połączenia. Chociaż wystarczą tu
najprostsze narzędzia (niemal każdy klient HTTP jest w stanie wyświetlić
uzyskaną przepływność), jest to najtrudniejsza płaszczyzna testów. O ile w
przypadku obserwacji pojedynczych PDU i ich sekwencji większość testów można
automatycznie wygenerować z dokumentacji protokołu, to zbadanie kwestii
wydajności jest bardzo trudne bez udziału człowieka.

W tego typu testach sama implementacja odgrywa istotną rolę, ale ogromne
znaczenie ma też wpływ środowiska i to użytkownik musi zadecydować o tym, jakie
warunki chcemy badać, bo tylko on zna przeznaczenie tworzonego oprogramowania.
Test w tym przypadku nie polega na zatwierdzeniu lub odrzuceniu pojedynczego
przypadku, a na analizie wielokrotnie powtarzanych eksperymentów i odniesieniu
wyników do teoretycznych założeń. Wiedza ekspercka jest tu nieodzowna.
Narzędzia do testowania wydajności nie powinny więc wyręczać człowieka, ale
wspierać go ułatwiając konfigurację środowiska, obsługę wielu urządzeń
jednocześnie i katalogowanie wyników.

\section{Testy w warunkach rzeczywistych, a symulacje}

Jest jasne, że eksperymenty najwygodniej przeprowadza się w sterylnych
warunkach laboratorium. Błędem jest jednak oczekiwanie, że produkt będzie
zachowywał się identycznie w normalnym użytkowaniu, a inżynieria oprogramowania
zaleca nawet wykonywanie testowej instalacji wdrożeniowej, aby zaobserwować
powstające różnice. Testy wykonywane w warunkach rzeczywistych mają zarówno
wady jak i zalety.  Wracając do omówionych powyżej rodzajów testów, można
powiedzieć, że w zależności od testu pożądane będą różne warunki jego
wykonania.

Aby sprawdzić czy algorytm generuje poprawne PDU najwygodniej jest skorzystać
ze środowiska testowego, debuggera czy symulatora. Opóźnienia związane z realną
transmisją są niepotrzebne, a nawet nieporządane. Możemy nawet uruchomić
algorytm osobno, poza stosem sieciowym, i analizować jego działanie
niezależnie. W przypadku sekwencji komunikatów również wystarczy symulowanie
uczestników komunikacji, gdyż zakładając poprawne działanie pozostałych
elementów sieci, skupimy się w ten sposób na danym algorytmie.

Test w warunkach rzeczywistych zawsze będzie wartościowym uzupełnieniem,
ponieważ na symulatorze możemy zapomnieć o takich problemach jak przekłamania
bitów czy gubienie PDU, a tworzone oprogramowanie powinno być na te zjawiska
odporne. Najlepszym scenariuszem byłoby testowanie dwóch powyższych
jednocześnie z wydajnością, ale jednoczesna analiza może prowadzić do
otrzymania złych wyników. Wydajność może być niższa od rzeczywistej z powodu
narzutu związanego ze sprawdzaniem komunikacji.

Pomiar wydajności w warunkach symulowanych dostarcza cennych informacji na
temat wymagań stawianych procesorowi czy pamięci. Trzeba mieć jednak na uwadze,
że otrzymywane wyniki mają szczególny charakter i nie należy ich przekładać na
oczekiwane zachowania w rzeczywistych sieciach. Dostępna obecnie moc
obliczeniowa pozwala symulować wiele czynników występujących w prawdziwych
sieciach, można więc coraz więcej testów przeprowadzać w środowiskach
wirtualnych. Uważamy jednak, że mnogość czynników, które trzeba uwzględnić,
wciąż przemawia na korzyść testów w warunkach rzeczywistych. Te czynniki to
między innymi:
\begin{itemize}
\item zawodność sprzętu,
\item wpływ innych użytkowników,
\item opóźnienia,
\item problem synchronizacji,
\item kwestie bezpieczeństwa.
\end{itemize}

Mimo, że powinno się myśleć o tych problemach jak o przeszkodach, to właśnie
fakt ich występowania jest powodem, dla którego test przeprowadzamy. Zjawiska
te, z natury nieprzewidywalne, uderzają w założenia o powtarzalności testu. Z
tego powodu należy monitorować i w miarę możliwości odnotowywać ich wpływ, aby
w zebranych wynikach móc poszukiwać relacji tłumaczących ewentualne zmiany w
obserwowanym zachowaniu. Trzeba też pamiętać, że zbierane wyniki nabierają
charakteru statystycznego i aby stały się wiarygodne, testy należy wielokrotnie
powtarzać.

\section{Dostępne rozwiązania}

Istnieje wiele programów rozwiązujących problem automatyzacji testowania, które
w różnym stopniu i na różnych poziomach pozwalają na ułatwienie i przyspieszenie
przeprowadzania testów aplikacji i protokołów sieciowych. Jednak spośród znanych
nam rozwiązań, żadne nie pozwalało przeprowadzić takiego rodzaju testów, jakie
próbowaliśmy wykonać.

\subsection{ASN.1 i ECN}
ASN.1 (Abstract Syntax Notation One) jest to standard ITU-T/ISO służący do opisu
struktur reprezentujących dane w sposób umożliwiający ich kodowanie, transmisję
i dekodowanie. Dostarcza on formalnej notacji do opisu struktur w sposób
niezwiązany z reprezentacją sprzętową.

ASN.1 definiuje sposób opisu danych. Jest on niezależny od metod ich kodowania,
przedstawionych w oddzielnych dokumentach. Przykładowe metody to:
\begin{itemize}
\item BER (Basic Encoding Rules),
\item PER (Packed Encoding Rules),
\item XER (XML Encoding Rules).
\end{itemize}

Wykorzystanie formalnych metod opisu pozwala na automatyczne tworzenie koderów i
dekoderów. W przypadku pracy z istniejącymi protokołami, PDU zwykle na stałe
wiąże przenoszone dane z ich kodowaniem. Przykładem może być opis pakietów TCP w
RFC 793, gdzie dane (np. numer sekwencyjny) i ich kodowanie (rozmiar i
położenie bitów w pakiecie) określone są w tym samym miejscu. Nie ma więc
podziału między semantyką informacji i jej bitową reprezentacją. Korzystanie z
ASN.1 w takich wypadkach jest trudniejsze, ale możliwe dzięki ECN.

ECN (Explicit Coding Notation) umożliwia formalny opis niestandardowych metod
kodowania. Jest to standard ściśle związany z ASN.1 i opis danego kodowania
zawsze łączy się z pewnym opisem danych wyrażonych w ASN.1. Z tego powodu często
spotyka się określenie ASN.1+ECN.

\subsubsection{Przykład}

Prezentujemy tutaj proste przykłady użycia ASN.1 oraz ASN.1+ECN. Zostały one
pobrane z materiałów szkoleniowych dostępnych w internecie. \fixme{Link? Odesłanie do bibliografii?}

Poniżej definiujemy prosty protokół składający się z jednego typu PDU:
(\code{Message}). Wiadomość zbudowana jest z identyfikatora oraz jej
zawartości, będącej napisem zakodowanym w UTF-8.

\begin{textcode}
  Protocol DEFINITIONS ::= BEGIN
       Message::= SEQUENCE {
          identifier INTEGER,
          content    UTF8String
      }
  END
\end{textcode}

Taka definicja, po wybraniu kodowania, może zostać użyta do wygenerowania
odpowiednich koderów i dekoderów, aby następnie użyć jej w tworzonej aplikacji.
Dekoder zgłaszający wszelkie napotkane błędy jest doskonałym narzędziem do
przetestowania pracy innego uczestnika komunikacji (którego poprawną
implementację chcemy zweryfikować).

PDU powyższego protokołu może mieć taką postać:

\begin{textcode}
  sampleMessage Message ::= {
      identifier     3,
      content        "Hello!"
  }
\end{textcode}

Istotną cechą ASN.1 jest odseparowanie definicji danych od ich kodowania.
Dzięki temu możliwe jest zakodowanie tych samych informacji na różne sposoby. I
tak np. możemy użyć kodowania XER uzyskując poniższy XML:

\begin{xmlcode}
  <Message>
      <identifier>3</identifier>
      <content>Hello!</content>
  </FooQuestion>
\end{xmlcode}

Czasem żadne z dostępnych, uniwersalnych, kodowań nie będzie odpowiadać naszym
wymaganiom. Dzieje się tak najczęściej w przypadku protokołów sztywno
definiujących sposób kodowania informacji, jak np. wspomniany wcześniej TCP. W
takich wypadkach możemy zastosować ECN.

ECN dostarcza mechanizmów do zdefiniowania dowolnego sposobu kodowania
informacji. Założmy, że w PDU naszego protokołu występuje liczba przyjmująca
wartości od 0 do 7 i używamy kodowania PER. Taka liczba zostałaby zakodowana
koszytając z 3 bitów. Ze względu jednak na przewidywaną możliwość rozwoju
chcemy aby zakodowana ona była na 5 bitach. Oto jak możemy to zrobić przy
pomocy ECN.

Najpierw definicja typu w ASN.1:

\begin{textcode}
  Example-ASN1 DEFINITIONS AUTOMATIC TAGS ::=
  BEGIN
    MyType ::= INTEGER (0..7)
  END
\end{textcode}

A następnie definicja kodowania w ECN:

\begin{textcode}
  Example-EDM ENCODING-DEFINITIONS ::=
  BEGIN
  
  IMPORTS
    #MyType
  FROM Example-ASN1;
  
  MyEncodings #ENCODINGS ::= { myType-encoding }
  
  myType-encoding #MyType ::= {
    ENCODING {
      ENCODING-SPACE
      SIZE 5
      MULTIPLE OF bit
      ENCODING positive-int
    }
  }
  END
\end{textcode}

Aby tej definicji użyć potrzebny jest jeszcze moduł łączący zdefiniowane kodowanie z definicją w ASN:

\begin{textcode}
  Example-ELM LINK-DEFINITIONS ::=
  BEGIN
  
  IMPORTS
    #MyType
  FROM Example-ASN1
    MyEncodings
  FROM Example-EDM;
  
  ENCODE #MyType
    WITH          MyEncodings
    COMPLETED BY  PER-BASIC-UNALIGNED
  END
\end{textcode}

Instrukcja \code{COMPLETED BY} powoduje, że do pozostałych danych zostaną użyte
standardowe reguły kodowania PER.

Oczywiście możliwości ECN są o wiele większe i biorą pod uwagę wszystkie
spotykane w praktyce sposoby kodowania złożonych struktur, jak określanie
sposobu budowania sekwencji, wybierania typu opcji, obliczanie sum kontrolnych,
wprowadzanie wyrównań, itd.

\subsubsection{Podsumowanie}

Język ASN.1 doskonale nadaje się do tworzenia dokumentacji, z której następnie
automatycznie można generować kodery i dekodery. Dzięki temu potrzebny do
testowania parser otrzymujemy niemal zerowym kosztem.

Uważamy, że jest to jedna z technologii, która z powodzeniem może być użyta do
przeprowadzania pierwszego rodzaju testów, badających poprawność PDU.

\subsection{TTCN}

TTCN-3 (Testing \& Test Control Notation v.~3) to język skryptowy stworzony i
rozwijany przez grupę TC-MTS (Methods for Testing and Specification Technical
Committee) w ramach ETSI.

Język swoimi korzeniami (TTCN-2) sięga do lat 80 minionego wieku. Wersja 3
została zaprojektowana z myślą o tych samych zastosowaniach, korzystając z wielu
lat doświadczeń, porzucono jednak sporo archaicznych rozwiązań (wprowadzono
m.in. nową składnię). Dzisiaj TTCN to język używany od ponad 15 lat w procesach
standaryzacji i przemyśle. Użyty został np. w czasie prac nad SIP i WiMAX.

TTCN-3 najlepiej sprawdza się w testach zgodności systemów komunikacyjnych
postrzeganych jako czarne skrzynki. Nie był projektowany z myślą o testach
wydajnościowych, chociaż obecnie projektowane są rozszerzenia mające na celu
zaadresować tego typu zastosowania.

\subsubsection{System testowy TTCN-3}

Testowanie przy użyciu TTCN-3 opiera się na wykonywaniu zaimplementowanych
komponentów, które, działając w interakcji z testowanych systemem, obserwują
komunikację i zgłaszają nieprawidłowości.

Komponenty przygotowuje się korzystając z języka TTCN-3, następnie translator
generuje kod w języku ogólnego przeznaczenia, który jest kompilowany powszechnie
dostępnymi narzędziami i łączony z biblioteką TTCN. Gotowe komponenty wykonywane
są jako samodzielne programy lub interpretowane w maszynie wirtualnej TTCN-3.

Interfejsem komunikacyjnym komponentów są porty. Warstwowa budowa systemu
pozwala oddzielić implementację od docelowego systemu. Dzięki wprowadzeniu
pośrednich adapterów możliwe jest łączenie portów poszczególnych komponentów ze
sobą (aby testować sam protokół) lub portami działających węzłów, co umożliwia
np. testowanie implementacji stosu TCP/IP systemu operacyjnego.

\subsubsection{Przykład}

Załóżmy, że tworzony przez nas komponent (np. urządzenie sprzętowe) ma za
zadanie natychmiast odsyłać (echo) odbierane dane. Chcemy zweryfikować tę
cechę. Dodatkowo, ponieważ w przypadku gdy błędnie pracujący komponent w ogóle
by nie odpowiedział, czekalibyśmy w nieskończoność na wynik, wprowadzamy limit
czasowy równy jednej sekundzie.

Poniżej prezentujemy przykład zaczerpnięty z materiałów szkoleniowych
TTCN. \fixme{link? bibliografia?}

W teście tym definiujemy komponent \code{MainComponent} wyposażony w jeden port
komunikacyjny oraz zegar, który użyty jest do implementacji limitu czasowego.

Nasz kompoment, w celu uruchomienia, wymaga środowiska systemowego. TSI (Test
System Interface) zapewnia komunikację z testowanym komponentem, w terminologii
TTCN nazywanym SUT (System Under Test). Dzięki tym dwóm konceptom możemy
połączyć naszą "wirtualną" maszynę testującą z rzeczywistym komponentem, który
chcemy testować, korzystając z mechanizmów dostarczanych przez odpowiedni
adapter oraz system operacyjny.

\begin{textcode}
  type port PortType mixed { inout all; }
  
  type component MainComponent
  {
      port PortType p;
      timer T_WAIT := 1.0;
  }
  
  type component TSI_Type
  {
      port PortType tsiPort;
  }
\end{textcode}

Obie definicje łączymy tworząc przypadek testowy:

\begin{textcode}
  testcase TC_send() runs on MainComponent system TSI_Type
  {
      map(mtc:p, system:tsiPort);
  
      p.send(10);
      T_WAIT.start;
  
      alt
      {
          [] p.receive(10)
          {
              setverdict(pass);
          }
  
          [] p.receive /* any */
          {
              setverdict(fail);
          }
  
          [] T_WAIT.timeout
          {
              setverdict(fail);
          }
      }
  }
\end{textcode}

Powyższy kod stwierdza, że test został spełniony (\code{setverdict(pass)})
jeśli na porcie \code{p} otrzymamy, wcześniej wysłaną, wartość \code{10}.
Jeżeli otrzymamy cokolwiek innego test się nie powiedzie
(\code{setverdict(fail)}).  Tak samo postępujemy, jeśli przekroczymy wcześniej
określony limit czasowy.

Tak przygotowany test tłumaczy się na kod, np. w C++, który po skompilowaniu i
zlinkowaniu z biblitekami TTCN jest gotowy do uruchomienia.

Zależnie od wybranych adapterów komunikacyjnych, możemy wybrać, gdzie
faktycznie zostaną wysłane dane. Mogą to być inne urządzenia, jeśli np.
testujemy implementację protokołu działającą na routerze sprzętowym lub inny
komponent TTCN, dzięki czemu uzyskujemy możliwość tworzenia prototypowych
implementacji protokołów. Możliwości są nieograniczone ponieważ możemy
dostarczyć własny adapter komunikacyjny.

\subsubsection{Podsumowanie}

TTCN jest dojrzałym i powszechnie używanym narzędziem. Jego możliwości pozwalają
w prosty sposób, dogłębnie testować komunikację na poziomie sekwencji
komunikatów. Uważamy, że rozwiązanie to wyczerpuje problematykę związaną z
mechanizmami pracy protokołu.

Obecnie narzędzie to nie pozwala na testowanie wydajności. Przygotowywane
rozwiązania są w fazie planowania. Dodatkowo, w celu zbadania wyłącznie
wydajności, nie jest potrzebne stosowanie niskopoziomowego TTCN. Można założyć,
że komunikacja między testowanymi komponentami przebiega według ustalonych
reguł, po czym obserwować jej efektywność.

\subsection{OMNeT++}

OMNeT++ to biblioteka i framework do tworzenia symulacji sieci. Użytkownik może korzystać z
szerokiej gamy modułów oraz tworzyć własne. Środowisko to wspiera symulacje
sterowane zdarzeniami przesyłanymi między występującymi w realizowanej sieci
komponentami. Istnieje szereg narzędzi zbudowanych na bazie środowiska OMNeT++,
które zostały stworzone z myślą o konkretnych rodzajach sieci, jak np. OverSim
będący symulatorem sieci peer2peer.

\begin{figure}
\begin{center}
\leavevmode
\includegraphics[width=0.8\textwidth]{intro-omnet-network}
\end{center}
\caption{Wizualizacja przebiegu symulacji w sieci złożonej z sześciu węzłów.
OMNeT++ umożliwia pełną instrumentację uruchomionego modelu. Na rysunku widać
(czerwona kropka) właśnie przesyłany komunikat.}
\label{fig:intro-omnet-network}
\end{figure}

Framework umożliwia pracę w IDE opartym na Eclipse i wspiera wiele pożądanych
funkcji jak np.~symulacje w czasie rzeczywistym czy integracja z bazą danych.
Tworzone symulacje można wykonywać jako samodzielne programy sterowane z linii
polecenia, aby zyskać na szybkości, lub pod kontrolą interfejsu graficznego
umożliwiającego dokładny wgląd w stan każdego elementu systemu.

Jest to program umożliwiający realizację i analizę prototypowych implementacji,
jak np.~algorytmów routingu. Nie został zaprojektowany z myślą o symulacji
złożonych systemów, takich jak pełna implementacja stosu sieciowego w systemie
operacyjnym. Tego typu realizacje są możliwe, ale działają niewydajnie.

\subsubsection{Przykład}

Pełna konfiguracja testu dla środowiska OMNeT++ jest zbyt złożona, żeby ją tu w
całości przytaczać. Prezentujemy tylko wybrane fragmenty.

Podstawowe moduły, tj. takie, których działanie programuje użytkownik,
definiowane są dyrektywą \code{simple}. Poniżej przykład komponentu o nazwie
\code{EtherMAC}. Zawiera on parametr \code{address}, którego wartość można
podać uruchamiając test lub zapisać w pliku konfiguracyjnym. Zdefiniowane są
także porty służące do komunikacji z innymi modułami. W tym wypadku warstwą LLC
oraz łącza danych.

\begin{textcode}
  simple EtherMAC {
      parameters:
          string address;
      gates:
          input phyIn;
          output phyOut;
          input llcIn;
          output llcOut;
  }
\end{textcode}

Komponenty typu \code{simple} można składać tworząc większe moduły, których
zadaniem jest organizacja podstawowych komponentów i definiowanie połączeń
między nimi.

Poniższy kod pokazuje jak z komponentów \code{EtherTrafficGen}, \code{EtherLLC}
oraz \code{EtherMAC} tworzony jest moduł \code{EtherStation}.

\begin{textcode}
  module EtherStation {
      parameters: ...
      gates: ...
          input in;
          output out;  
      submodules:
          app: EtherTrafficGen;
          llc: EtherLLC;
          mac: EtherMAC;
      connections:
          app.out --> llc.hlIn;
          app.in <-- llc.hlOut;
          llc.macIn <-- mac.llcOut;
          llc.macOout --> mac.llcIn;
          mac.phyIn <-- in;
          mac.phyOut --> out;
  }
\end{textcode}

Aby przykład był kompletny, należałoby jeszcze zdefiniować sieć i jej
topologię.  Powyższy moduł zawiera definicje dwóch portów (sekcja
\code{gates}), które mają posłużyć właśnie połączeniu z innymi komponentami
(np. modelującymi hub). Dodatkowo całość potrzebuje konfiguracji
uruchomieniowej. Graficzne środowisko ułatwia tworzenie tych brakujących elementów.

\begin{figure}
\begin{center}
\leavevmode
\includegraphics[width=0.8\textwidth]{intro-omnet-histogram}
\end{center}
\caption{Poza umożliwieniem uruchomienia zdefiniowania i uruchomienia
symulacji, pakiet OMNeT++ zawiera także narzędzia ułatwiające gromadzenie
danych statystycznych oraz graficzną analizę wyników. Na rysunku widać
przykładowy histogram uzyskany po wykonaniu testu.}
\label{fig:intro-omnet-histogram}
\end{figure}

\subsubsection{Podsumowanie}

OMNeT++ to rozbudowane środowisko umożliwiające tworzenie testów modelujących
złożone systemy. Pracę wspiera graficzny interfejs oraz framework
udostępniający szeroką gamę najczęściej potrzebnych funkcji.

Pewną wadą jest niska wydajność w sytuacji, gdy modeluje się systemy z dużą
liczbą komponentów intensywnie się komunikujących.

\subsection{Podsumowanie}

Przeprowadzenie testu w środowisku rozproszonym dostarcza nowego rodzaju
trudności związanych z koniecznością obsługi wielu urządzeń. Dostępne
rozwiązania najczęściej tworzone są z myślą o testowaniu w warunkach
symulacyjnych, gdzie całą sieć odtwarzamy na pojedynczym komputerze. Tego typu
testy są pomocne, jednak nie wyczerpują całego spektrum zastosowań.

Środowisko rzeczywistej sieci zachowuje się inaczej niż symulator. Zarówno ze
względu na cechy fizyczne, jak też realne rozproszenie maszyn, a co za tym
idzie inny sposób dostępu do nich. Trzeba też pamiętać, że aplikacje często
osiągają inne wyniki, kiedy pracują w realnej sieci i komunikują się między
sobą, a nie z symulatorem.

Nie dotarliśmy do programu, który ułatwiałby wykonanie testów w
rzeczywistych sieciach, gdzie problemy takie jak synchronizacja urządzeń i
zbieranie wyników powodują, że ręczne wykonywanie wszystkich czynności staje
się bardzo czasochłonne i uciążliwe, choć sam test jest w swojej naturze prosty.

W tabeli \fixref{tej poniżej} porównujemy naszym zdaniem najistotniejsze cechy
wspomnianych narzędzi. Jak widać Arete nie jest idealnym narzędzie do każdego
typu zastosowań. Nie jest to również narzędzie zdolne do samodzielnej pracy.
Uważamy jednak, że dobrze uzupełnia funkcjonalne braki istniejących rozwiązań i
razem z nimi pozwala stworzyć praktyczne i wygodne środowisko testowe.

\begin{small}
\begin{center}
   \begin{tabular}{ l || C{1.1cm} | C{1.1cm} | C{1.1cm} | C{1.1cm}   }
      \hline
      & \small{\parbox[top][2.4em][c]{1.1cm}{\centering{ASN.1+\\ECN}}} & \small{TTCN} & \small{OMNeT} & \small{Arete} \\
      \hline
      Powtarzanie eksperymentów & $+$ & $+$ & $+$ & $+$ \\
      \hline
      Deterministyczne wyniki & $+$ & $+$ & $+$ & $-$ \\
      \hline
      Weryfikacja wyników & $+$ & $+$ & $-$ & $-$ \\
      \hline
      Uwzględnienie wpływu środowiska & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Wykorzystanie rzeczywistych urządzeń & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Testy wymienianych PDU & $+$ & $+$ & $+$ & $-$ \\
      \hline
      Testy sekwencji komunikatów & $-/+$ & $+$ & $+$ & $-/+$ \\
      \hline
      Testy wydajnościowe & $-$ & $+$ & $-$ & $+$ \\
      \hline
      Brak wpływu na wydajność & $-$ & $-$ & $-$ & $+$ \\
      \hline
      Możliwość rozwijania narzędzia & $-$ & $-/+$ & $+$ & $+$ \\
      \hline
      Dostępne darmowo & $-/+$ & $-$ & $-/+$ & $+$ \\
      \hline
      Łatwość nauki & $-$ &  $+$ & $+$ & $+$ \\
      \hline

  \end{tabular}
\end{center}
\end{small}

\end{document}
