\documentclass[00-praca-magisterska.tex]{subfiles}

\begin{document}

\chapter{Wprowadzenie}

Inżynieria oprogramowania bardzo szeroko omawia tematykę testów, na każdym
kroku podkreślając wagę i nieodłączność tej fazy w procesie tworzenia.
Powstający produkt testuje się, aby zapewnić jak najwyższą jakość dostarczanego
oprogramowania. Pod tym ogólnym stwierdzeniem często rozumie się co innego, w
zależności od rodzaju i przeznaczenia programu. Dlatego też w tym rozdziale
przybliżamy zakres zagadnień, na którym skupimy się w pracy.

\section{Dlaczego testujemy}

Oprogramowanie testuje się, żeby sprawdzić jego poprawność. Twórcy zależy na
tym, żeby zminimalizować ilość swoich błędów. Odbiorca natomiast chciałby
potwierdzenia, że otrzymuje produkt, jakiego oczekiwał. Pod tymi słowami kryje
się za każdym razem inny konkret, któremu się przyglądamy, jednak kilka
ogólnych cech pozostaje niezmiennych.

Pierwszą taką cechą jest weryfikacja mierzalnej wartości. Każdy test powstaje w
celu sprawdzenia czy oczekiwane przewidywania są spełnione. Wymagane jest więc
określenie jakich wartości oczekujemy od poszczególnych czynników. Biorąc za
przykład popularny ostatnio ,,szybki Internet'' łatwo pokazać, że samo nazwanie
czegoś szybkim nie przedstawia żadnej cennej informacji, gdyż mówiąc potocznie,
dostawcy usług zawsze dostarczają najszybszego Internetu, a mimo to z roku na
rok udaje się zapewnić jeszcze szybsze łącza.

Obiektywne sformułowanie przedmiotu testu wymienia nie tylko badaną wielkość,
ale też oczekiwaną wartość. Mówienie o szybkości transferu ma sens, kiedy
padają konkretne liczby, ponieważ wtedy można je porównać z przewidywaniami i
stwierdzić czy dana szybkość nas zadowala.

Może zdarzyć się, że nie taka wartości odniesienia nie istnieje. Przy pierwszym
pomiarze czasu wykonania nowego algorytmu możemy tylko zgadywać lub
subiektywnie oceniać go w świetle podobnych algorytmów. W kolejnych pomiarach
dysponujemy już jednak poprzednią wartością i możemy wnioskować z jej pomocą.
Niezmienny jest jednak fakt, że sprawdzamy wielkość, którą można zmierzyć i
nasze pomiary nie są zaburzone naszą osobistą oceną.

Możliwość dokonania kolejnego pomiaru jest drugą bardzo istotną cechą
testu\footnote{Istnieje szereg testów, których charakter uniemożliwia ich
powtórzenie lub czyni je kosztownym. Sprzęt sieciowy na szczęście nie ulega
zniszczeniu w czasie większości testów.}. Dzięki temu jesteśmy w stanie ocenić
jak na wyniki wpływają takie czynniki jak sprzęt czy zmiany w oprogramowaniu.

Uruchomienie tego samego testu na różnego rodzaju urządzeniach pozwala
stwierdzić czy tworzone rozwiązanie jest przenośne, czy się skaluje, czy
sprawdza się w ekstremalnych warunkach itp. W zastosowaniach związanych z
sieciami komputerowymi tego typu testy są szczególnie istotne ze względu na
różnorodność dostępnych urządzeń i protokołów.

Zmiany w oprogramowaniu są naturalne. Zmienia się je tworząc, poprawiając i
rozbudowując. Możliwość wielokrotnego testowania funkcjonalności pozwala ocenić
ją w świetle wprowadzanych zmian. Najpierw można przekonać się o tym, że
pożądana cecha została osiągnięta. Następnie, w przypadku poprawek istniejącego
produktu, możemy przekonać się, że problemy zostały usunięte, a także, że ich
eliminacja nie zaburzyła innych komponentów. To samo dotyczy nowej
funkcjonalności. Mamy też możliwość oceny wpływu zmian na wydajność i to, przy
systematycznym wykonywaniu testów, na przestrzeni życia całego projektu.

Ponieważ w środowiskach rozproszonych powszechna jest sytuacja, w której mamy
do czynienia ze sprzętem różnego rodzaju i różnych producentów, a budowane
rozwiązania mają niezawodnie pracować przez wiele lat, testowanie tworzonych
produktów jest tu bardzo istotne. Jednocześnie jest ono trudniejsze niż w
wypadku rozwiązań przeznaczonych na samodzielne\footnote{standalone} systemy.

\section{Testy aplikacji sieciowych}

W sieciach komputerowych oprogramowanie występuje wszędzie. Na różnych
warstwach modelu OSI powierza się mu różne zadania i inaczej je implementuje, a
od każdego składnika sieciowego stosu oczekujemy poprawnej pracy, którą
weryfikować można testami.

Inaczej wyglądają testy protokołu CSMA/CD, inaczej protokołu TCP, wreszcie
zupełnie inne są testy aplikacji synchronizującej kalendarz z urządzeniem
mobilnym. Z drugiej strony często można znaleźć elementy wspólne pomimo tego,
że badane implementacje realizują zupełnie inną funkcjonalność.

W dalszych rozważaniach skupimy się na podziale testów ze względu na rodzaj
obserwowanych wielkości, ponieważ niezależnie od warstwy, sposób ich pomiaru
jest podobny. Wyróżniliśmy następujące rodzaje testów:
\begin{itemize}
  \item{wymienianych PDU\footnote{Protocol Data Unit},}
  \item{sekwencji komunikatów,}
  \item{wydajności transmisji.}
\end{itemize}

Pierwszy rodzaj dotyczy budowy komunikatów wymienianych między urządzeniami. Są
to testy mające na celu sprawdzić czy przesyłane dane odpowiadają założeniom.
Badane są takie wielkości jak: długość PDU, zgodność sumy kontrolnej,
poprawność kodowania numeru wersji itp. Kontrola jakości na tym etapie ma na
celu zweryfikowanie, czy zbudowane PDU jest zgodne ze specyfikacją. Od
wykorzystywanych tu narzędzi wymaga się, aby umożliwiały sformalizowanie opisu
zawartego w dokumentacji do postaci, którą można algorytmicznie porównać z
obserwowanymi PDU.

Kiedy operujemy poprawnymi komunikatami, należy zadbać o poprawność ich
sekwencji. Skuteczna komunikacja najczęściej wymaga zachowania pewnej
kolejności i rodzaju przesyłanych PDU. Testy sprawdzają czy obserwowane grupy
komunikatów odpowiadają tym ze specyfikacji, np. czy numery potwierdzeń
odpowiadają numerom wysyłanych danych, czy na generowane zapytania otrzymujemy
odpowiedzi, czy komponent poprawnie reaguje na utracone lub przekłamane dane
itd. Od narzędzi wymaga się już nie tylko parsowania PDU, ale też
interpretowania ich zawartości i podążania za obserwowanym, globalnym stanem
połączenia.

Wydajność transmisji dotyczy między innymi osiąganych przepustowości, reakcji
na zatory, rywalizacji z innymi przepływami, jakości łączy fizycznych i innych
czynników mających wpływ na odczuwalną jakość połączenia. Chociaż wystarczą tu
najprostsze narzędzia (niemal każdy klient HTTP jest w stanie wyświetlić
uzyskaną prędkość transferu), jest to najtrudniejsza płaszczyzna testów.

Trudność polega na poprawnym zdefiniowaniu testu. O ile w przypadku obserwacji
pojedynczych PDU i ich sekwencji łatwo pokusić się o stwierdzenie, że cały test
można automatycznie wygenerować z dokumentacji protokołu, to kwestii wydajności
nie da się zbadać bez udziału człowieka.

W tego typu testach sama implementacja odgrywa istotną rolę, ale ogromne
znaczenie ma też wpływ środowiska i to człowiek musi zadecydować o tym, jakie
warunki chcemy badać, bo tylko on zna przeznaczenie tworzonego oprogramowania.

Ponadto test w tym przypadku nie polega na zatwierdzeniu lub odrzuceniu
pojedynczego przypadku, a na analizie wielokrotnie powtarzanych eksperymentów i
odniesieniu wyników do teoretycznych założeń. Wiedza ekspercka jest tu
nieodzowna.

Narzędzia do testowania wydajności nie powinny więc wyręczać człowieka, ale
wspierać go ułatwiając konfigurację środowiska, obsługę wielu urządzeń
jednocześnie i katalogowanie wyników.

\section{Testy w warunkach rzeczywistych}

Jest jasne, że eksperymenty najwygodniej przeprowadza się w sterylnych
warunkach laboratorium. Błędem jest jednak oczekiwanie, że produkt będzie
zachowywał się identycznie w normalnym użytkowaniu, a inżynieria oprogramowania
zaleca nawet wykonywanie testowej instalacji wdrożeniowej, aby zaobserwować
powstające różnice.

Testy wykonywane w warunkach rzeczywistych mają zarówno wady jak i zalety.
Wracając do omówionych powyżej rodzajów testów, można powiedzieć, że w
zależności od testu pożądane będą różne warunki jego wykonania.

Aby sprawdzić czy algorytm generuje poprawne PDU najwygodniej jest skorzystać
ze środowiska testowego, debuggera czy symulatora. Nie potrzebujemy i nie
chcemy opóźnień związanych z realną transmisją. Możemy nawet uruchomić algorytm
osobno, poza stosem sieciowym, i patrząc z boku analizować jego działanie.

W przypadku sekwencji komunikatów również wystarczy nam symulowanie
uczestników komunikacji, gdyż zakładając poprawne działanie pozostałych
elementów sieci, skupimy się w ten sposób na danym algorytmie.

Test w warunkach rzeczywistych zawsze będzie wartościowym uzupełnieniem,
ponieważ na symulatorze możemy zapomnieć o takich problemach jak przekłamania
bitów czy gubienie PDU, a tworzone oprogramowanie powinno być na te zjawiska odporne.

Chciałoby się jednocześnie z dwoma powyższymi testować także wydajność, ale
jednoczesna analiza może prowadzić do otrzymania złych wyników. Wydajność może
być niższa od rzeczywistej z powodu narzutu związanego ze sprawdzaniem
komunikacji.

Pomiar wydajności w warunkach symulowanych dostarcza cennych informacji na
temat wymagań stawianych procesorowi czy pamięci. Trzeba mieć jednak na uwadze,
że otrzymywane wyniki mają szczególny charakter i nie należy ich przekładać na
oczekiwane zachowania w rzeczywistych sieciach. 

Obecnie moc obliczeniowa pozwala symulować wiele czynników występujących w
prawdziwych sieciach. Można więc coraz więcej testów przeprowadzać w
wirtualnych środowiskach. Uważamy jednak, że mnogość czynników, które trzeba
uwzględnić, wciąż przemawia na korzyść testów w warunkach rzeczywistych.

Te czynniki to między innymi:
\begin{itemize}
\item zawodność sprzętu,
\item wpływ innych użytkowników,
\item opóźnienia,
\item problem synchronizacji,
\item kwestie bezpieczeństwa.
\end{itemize}

Błędem jest myślenie o tych problemach jak o przeszkodach, które należy
wyeliminować aby otrzymać poprawne środowisko testowe. To właśnie fakt ich
występowania jest powodem, dla którego test przeprowadzamy. Zjawiska te, z
natury nieprzewidywalne, uderzają w założenia o powtarzalności testu. Z tego
powodu należy monitorować i w miarę możliwości odnotowywać ich wpływ, aby w
zebranych wynikach móc poszukiwać relacji tłumaczących ewentualne zmiany w
obserwowanym zachowaniu. Trzeba też pamiętać, że zbierane wyniki nabierają
charakteru statystycznego i aby stały się wiarygodne, testy należy wielokrotnie
powtarzać.

\section{Dostępne rozwiązania}

Nie jesteśmy pierwszymi ludźmi, którzy zauważyli ten problem i dostępnych jest
wiele programów adresujących go. Jednak spośród znanych nam rozwiązań, żadne
nie pozwalało przeprowadzić takiego rodzaju testów, jakie próbowaliśmy wykonać.

\subsection{ASN.1}
ASN.1 (Abstract Syntax Notation One) jest to standard ITU-T/ISO służący do opisu
struktur reprezentujących dane w sposób umożliwiający ich kodowanie, transmisję
i dekodowanie. Dostarcza on formalnej notacji do opisu struktur w sposób
niezwiązany z reprezentacją sprzętową.

ASN.1 definiuje sposób opisu danych. Jest on niezależny od metod ich kodowania,
przedstawionych w oddzielnych dokumentach. Przykładowe metody to:
\begin{itemize}
\item BER (Basic Encoding Rules),
\item PER (Packed Encoding Rules),
\item XER (XML Encoding Rules).
\end{itemize}

Wykorzystanie formalnych metod opisu pozwala na automatyczne tworzenie koderów i
dekoderów. W przypadku pracy z istniejącymi protokołami, PDU zwykle na stałe
wiąże przenoszone dane z ich kodowaniem. Przykładem może być opis pakietów TCP w
RFC 793. Gdzie dane (np. numer sekwencyjny) i ich kodowanie (rozmiar i położenie
bitów w pakiecie) określone są jednocześnie. Korzystanie z ASN.1 w takich
wypadkach jest trudniejsze, ale możliwe dzięki ECN.

ECN (Explicit Coding Notation) umożliwia formalny opis niestandardowych metod
kodowania. Jest to standard ściśle związany z ASN.1 i opis danego kodowania
zawsze łączy się z pewnym opisem danych wyrażonych w ASN.1. Z tego powodu często
spotyka się określenie ASN.1+ECN.

%\subsubsection{Podsumowanie}

Język ASN.1 doskonale nadaje się do tworzenia dokumentacji, z której następnie
automatycznie można generować kodery i dekodery. Dzięki temu potrzebny do
testowania parser otrzymujemy niemal zerowym kosztem.

Uważamy, że jest to jedna z technologii, która z powodzeniem może być użyta do
przeprowadzania pierwszego rodzaju testów, badających poprawność PDU.

\subsection{TTCN}

TTCN-3 (Testing \& Test Control Notation v.~3) to język skryptowy stworzony i
rozwijany przez grupę TC-MTS (Methods for Testing and Specification Technical
Committee) w ramach ETSI.

Język swoimi korzeniami (TTCN-2) sięga do lat 80 minionego wieku. Wersja 3
została zaprojektowana z myślą o tych samych zastosowaniach, korzystając z wielu
lat doświadczeń, porzucono jednak sporo archaicznych rozwiązań (wprowadzono
m.in. nową składnię). Dzisiaj TTCN to język używany od ponad 15 lat w procesach
standaryzacji i przemyśle. Użyty został np. w czasie prac nad SIP i WiMAX.

TTCN-3 najlepiej sprawdza się w testach zgodności systemów komunikacyjnych
postrzeganych jako czarne skrzynki. Nie był projektowany z myślą o testach
wydajnościowych, chociaż obecnie projektowane są rozszerzenia mające na celu
zaadresować tego typu zastosowania.

%\subsubsection{System testowy TTCN-3}

Testowanie przy użyciu TTCN-3 opiera się na wykonywaniu zaimplementowanych
komponentów, które, działając w interakcji z testowanych systemem, obserwują
komunikację i zgłaszają nieprawidłowości.

Komponenty przygotowuje się korzystając z języka TTCN-3, następnie translator
generuje kod w języku ogólnego przeznaczenia, który jest kompilowany powszechnie
dostępnymi narzędziami i łączony z biblioteką TTCN. Gotowe komponenty wykonywane
są jako samodzielne programy lub interpretowane w maszynie wirtualnej TTCN-3.

Interfejsem komunikacyjnym komponentów są porty. Warstwowa budowa systemu
pozwala oddzielić implementację od docelowego systemu. Dzięki wprowadzeniu
pośrednich adapterów możliwe jest łączenie portów poszczególnych komponentów ze
sobą (aby testować sam protokół) lub portami działających węzłów, co umożliwia
np. testowanie implementacji stosu TCP/IP systemu operacyjnego.

%\subsubsection{Podsumowanie}

TTCN jest dojrzałym i powszechnie używanym narzędziem. Jego możliwości pozwalają
w prosty sposób, dogłębnie testować komunikację na poziomie sekwencji
komunikatów. Uważamy, że rozwiązanie to wyczerpuje problematykę związaną z
mechanizmami pracy protokołu.

Obecnie narzędzie nie adresuje kwestii wydajności. Przygotowywane rozwiązania
są w fazie planowania. Dodatkowo, w celu zbadania wyłącznie wydajności, nie
jest potrzebne stosowanie niskopoziomowego TTCN. Można założyć, że komunikacja
między testowanymi komponentami przebiega według ustalonych reguł, po czym
obserwować jej efektywność.

\subsection{OMNeT++}

OMNeT++ to biblioteka i framework do tworzenia symulacji sieci. Użytkownik może
korzystać z szerokiej gamy modułów oraz tworzyć własne. Framework wspiera
symulacje sterowane zdarzeniami przesyłanymi między występującymi w
realizowanej sieci komponentami.

Istnieje szereg frameworków zbudowanych na bazie środowiska OMNeT++, a które
zostały stworzone z myślą o konkretnych rodzajach sieci, jak np. OverSim będący
symulatorem sieci peer2peer.

Framework umożliwia pracę w IDE opartym na Eclipse i wspiera wiele pożądanych
funkcji jak np.~symulacje w czasie rzeczywistych czy integracja z bazą danych.
Tworzone symulacje można wykonywać jako samodzielne programy sterowane linią
polecenia, aby zyskać na szybkości, lub pod kontrolą interfejsu graficznego
umożliwiającego dokładny wgląd w stan każdego elementu systemu.

Jest to program umożliwiający realizację i analizę prototypowych implementacji,
jak np.~algorytmów routingu. Nie został zaprojektowany z myślą o symulacji
złożonych systemów, takich jak pełna implementacja stosu sieciowego w systemie
operacyjnym. Tego typu realizacje są możliwe, ale działają niewydajnie.

Chociaż istnieje możliwość uruchomienia symulacji na kilku urządzeniach
jednocześnie, wykonywany kod pozostaje pod kontrolą środowiska OMNeT++.

Nie jest możliwy przypadek użycia, w którym za pomocą OMNeT++ sterujemy pracą
zdalnych systemów, wykonując na nich własną aplikację.

\subsection{Podsumowanie}

Przeprowadzenie testu w środowisku rozproszonym dostarcza nowego rodzaju
trudności związanych z koniecznością obsługi wielu urządzeń. Dostępne
rozwiązania najczęściej tworzone są z myślą o testowaniu w warunkach
symulacyjnych, gdzie całą sieć odtwarzamy na pojedynczym komputerze. Tego typu
testy są pomocne, jednak nie wyczerpują całego spektrum zastosowań.

Środowisko rzeczywistej sieci zachowuje się inaczej niż symulator. Zarówno ze
względu na cechy fizyczne, jak też realne rozproszenie maszyn, a co za tym
idzie inny sposób dostępu do nich. Trzeba też pamiętać, że aplikacje często
osiągają inne wyniki, kiedy pracują w realnej sieci i komunikują się między
sobą, a nie z symulatorem.

Nie dotarliśmy do programu, który ułatwiałby wykonanie testów w
rzeczywistych sieciach, gdzie problemy takie jak synchronizacja urządzeń i
zbieranie wyników powodują, że ręczne wykonywanie wszystkich czynności staje
się bardzo czasochłonne i uciążliwe, choć sam test jest w swojej naturze prosty.

\end{document}
